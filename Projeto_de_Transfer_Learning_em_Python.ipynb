{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1XVFcjbMStiOwIWXBKMXaH4tXKiiWbq8Y",
      "authorship_tag": "ABX9TyMIZihhdVzPEL6Gml3B5swL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbnerSilvaBarbosa/DIO-IA/blob/main/Projeto_de_Transfer_Learning_em_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importações"
      ],
      "metadata": {
        "id": "qgUvTwNizPTS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EejBLFZwzAH0",
        "outputId": "48933a77-e488-4993-b94c-4aeac11a8dcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow version: 2.15.0\n",
            "Num GPUs Available:  0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import zipfile\n",
        "import os\n",
        "import urllib.request\n",
        "\n",
        "# Verifica se está usando GPU\n",
        "print(\"Using TensorFlow version:\", tf.__version__)\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Definir o caminho do arquivo ZIP no Google Drive\n",
        "zip_file_path = '/content/drive/MyDrive/DIO IA/kagglecatsanddogs_5340.zip'\n",
        "extract_path = '/content/cats_and_dogs'\n",
        "\n",
        "# Extrair o arquivo ZIP\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# Verificar se a extração foi bem-sucedida\n",
        "!ls /content/cats_and_dogs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpOwSRp-2M2H",
        "outputId": "13978122-8e33-4fd5-dd29-abc719c8963a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            " CDLA-Permissive-2.0.pdf   PetImages  'readme[1].txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "original_dataset_dir = '/content/cats_and_dogs/PetImages'\n",
        "base_dir = '/content/cats_and_dogs_small'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "def create_small_dataset(original_dir, target_dir, category, num_samples):\n",
        "    category_dir = os.path.join(original_dir, category)\n",
        "    target_category_dir = os.path.join(target_dir, category)\n",
        "    os.makedirs(target_category_dir, exist_ok=True)\n",
        "\n",
        "    files = os.listdir(category_dir)[:num_samples]\n",
        "    for fname in files:\n",
        "        src = os.path.join(category_dir, fname)\n",
        "        dst = os.path.join(target_category_dir, fname)\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "create_small_dataset(original_dataset_dir, base_dir, 'Cat', 1000)\n",
        "create_small_dataset(original_dataset_dir, base_dir, 'Dog', 1000)\n",
        "\n",
        "train_dir = base_dir\n"
      ],
      "metadata": {
        "id": "8WpcKZT02shT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),  # Reduzindo o tamanho da imagem\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),  # Reduzindo o tamanho da imagem\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e24bD57u2wF6",
        "outputId": "b8f1631e-1eab-46db-fe11-0afbaedcc59b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1600 images belonging to 2 classes.\n",
            "Found 400 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xkm3yAgz5Ut9",
        "outputId": "3244c1a0-41f5-4d8b-85bd-43f78f833a7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=64,  # Aumentando o batch size\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=64,  # Aumentando o batch size\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMtHKJ8F5ang",
        "outputId": "a8b91663-83f0-4ff6-8457-cc2a5dbab929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1600 images belonging to 2 classes.\n",
            "Found 400 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar o modelo\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=5)]\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Avaliar o modelo\n",
        "val_loss, val_acc = model.evaluate(validation_generator)\n",
        "print(f'Validation accuracy: {val_acc * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJOyyInx201A",
        "outputId": "99bf56eb-e36e-4694-88de-90ba7818d9bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "25/25 [==============================] - 50s 2s/step - loss: 6.8905 - accuracy: 0.8019 - val_loss: 0.4373 - val_accuracy: 0.9325\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 46s 2s/step - loss: 0.1842 - accuracy: 0.9494 - val_loss: 0.2503 - val_accuracy: 0.9375\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 50s 2s/step - loss: 0.0601 - accuracy: 0.9812 - val_loss: 0.2055 - val_accuracy: 0.9400\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 50s 2s/step - loss: 0.0184 - accuracy: 0.9950 - val_loss: 0.1951 - val_accuracy: 0.9450\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 47s 2s/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9425\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 43s 2s/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.9425\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 43s 2s/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9425\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 45s 2s/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9425\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 45s 2s/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9425\n",
            "7/7 [==============================] - 6s 825ms/step - loss: 0.2012 - accuracy: 0.9425\n",
            "Validation accuracy: 94.25%\n"
          ]
        }
      ]
    }
  ]
}